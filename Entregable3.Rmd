---
title: "Entregable 3"
author: "Adrià García and Rubén Montagut"
date: \today
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_document:
    toc: no
    toc_depth: '4'
  word_document:
    toc: no
    toc_depth: '4'
geometry: left=1.9cm,right=1.9cm,top=1.25cm,bottom=1.52cm
fontsize: 18pt
subtitle: 'Numeric and Binary targets Forecasting Models'
classoption: a4paper
editor_options: 
  chunk_output_type: console
---

# Data Description: 100,000 UK Used Car Data set

  -   manufacturer	Factor: Audi, BMW, Mercedes or Volkswagen
  -   model	Car model
  -   year	registration year
  -   price	price in £
  -   transmission	type of gearbox
  -   mileage	distance used
  -   fuelType	engine fuel
  -   tax	road tax
  -   mpg	Consumption in miles per gallon   
  -   engineSize	size in litres


# Load Required Packages: to be increased over the course

```{r}
# Load Required Packages: to be increased over the course
options(contrasts=c("contr.treatment","contr.treatment"))
requiredPackages <- c("effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr")
#use this function to check if each package is on the local machine
#if a package is installed, it will be loaded
#if any are not, the missing package(s) will be installed and loaded
package.check <- lapply(requiredPackages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})
#verify they are loaded
search()
```

# Carreguem les dades modificades a l'últim entregable

```{r}
setwd("C:/Users/thekr/OneDrive/Documentos/R/workspace")
filepath<-"C:/Users/thekr/OneDrive/Documentos/R/workspace/"

load(paste0(filepath,"MyOldCars-5000Modif.RData"))
options(contrasts=c("contr.treatment","contr.treatment"))

save(df,file = "C:/Users/thekr/OneDrive/Documentos/R/workspace/MyOldCars-5000Del3.RData")
```
# Primer comprovem la normalitat de la nostra variable target

```{r}
hist(df$price,50,freq=F,col="orange",border = "orange")
mm<-mean(df$price)
ss<-sd(df$price)
curve(dnorm(x,mean=mm,sd=ss),col="red",lwd=2,lty=3, add=T)
shapiro.test(df$price)
```

Podem veure, pels resultats de l'histograma i del shapiro test, que el target "price" no segueix una distribució normal. Ja que no trobem simetria al gràfic i el p-value del test ens dona un número molt més petit de 0.05.

# Models linears: usant variables numèriques

```{r}
names(df)
vars_con<-names(df)[c(3,5,7,8,12)]
vars_dis<-names(df)[c(1:2,4,6,9,10)]
vars_res<-names(df)[c(3)]
vars_con
ll<-which(df$age==0);ll
df$age[ll]<-0.5
ll<-which(df$tax==0);ll
df$tax[ll]<-0.5
```


## Model 1:
```{r}
m1<-lm(price~mileage+tax+mpg+age,data=df)
summary(m1)
```
Com veiem al summary, segons el multiple R-Squared, el model explica el 51.8% de la variabilitat del target. Tot i que també veiem, amb el p-valor, que ho podem descartar.

```{r}
vif(m1) #Variance inflation factor: multicorrelation
```
Segons els resultats del vif, ens podem quedar amb totes les variables que estem usant fins ara.

```{r}
par(mfrow=c(2,2))
plot(m1,id.n=0)
```
Si veiem els gràfics, podem treure algunes conclusions:

- Tenim prou homocedasticitat, però per alguns valors de X si que hi ha Y molt separades de les altres (ex: 30000 o    40000).
- Al gràfic de distribució normal, podem veure com al final hi ha valors que se separen considerablement de la línea.
- De moment no tenim gaire heterodasticitat.

```{r}
par(mfrow=c(1,1))
library(MASS)
boxcox(price~mileage+tax+mpg+age,data=df)
```
Com el valor lambda és molt proper a 0, aplicarem una transformació logarítmica a la variable target "price".

## Model 2
```{r}
# New model:
m2<-lm(log(price)~mileage+tax+mpg+age,data=df)
summary(m2)
vif(m2) #Not changed because explanatory variables have not changed
```
Podem observar que la multiple R-squared (o la explicabilitat) ha augmentat, en aquest cas fins a 60.4%, per tant el model és més representatiu. El vif no ha canviat ja que estem usant les mateixes variables numèriques.

```{r}
summary(df$tax)
# Transformations to my regresors?
boxTidwell(log(price) ~ mileage+mpg+age,data=df[!df$mout=="YesMOut",])
# Power transformations of the predictors in a linear model
par(mfrow=c(2,2))
plot(m2,id.n=0)
```
Si mirem els gràfics obinguts, podem veure que ha millorat una mica la normalitat, pero la homocedasticitat i la heterodasticitat no. Per tant seguirem aplicant transformacions.
Hem fet el boxTidwell sense la variable "tax" ja que ens dona errors tot i no tenir cap valor fora del normal o esperat.

```{r}
par(mfrow=c(1,1))
residualPlots(m2,id=list(method=cooks.distance(m2),n=10)) 
marginalModelPlots(m2)
```

Segons el boxTidwell, aplicarem el logaritme a la variable mileage en el nou model.

## Model 3
```{r}
m3<-lm(log(price)~log(mileage)+mpg+age,data=df[!df$mout=="YesMOut",])
summary(m3)
# Validation and effects consideration:
Anova(m3) #Net effect test
vif(m3)
par(mfrow=c(2,2))
plot(m3,id.n=0)
```
En aquest tercer model, obtenim una explicabilitat del 56.7% (inferior a la dels altres models). Però les altres característiques, comprovades als gràfics QQNorm o Residuals vs Fitted, han millorat respecte l'anterior model.
També podem veure que la variable log(mileage) no depèn del valor del target price (vist tant a l'Anova com al summary).

```{r}
par(mfrow=c(1,1))
residualPlots(m3,id=list(method=cooks.distance(m3),n=10))
marginalModelPlots(m3)
df2 <- df[!df$mout=="YesMOut",]
df2 <- df2[row.names(df2)!="20136",]
df2 <- df2[row.names(df2)!="44596",]
df2 <- df2[row.names(df2)!="33222",]
df2 <- df2[row.names(df2)!="33260",]
df2 <- df2[row.names(df2)!="35343",]
```
Acabem d'eliminar tant els multivariate outliers com algunes observacions que podien ser causants d'empitjorar la normalitat del model.

## Model 4
```{r}
m4<-lm(log(price)~log(mileage)+mpg+age,data=df2)
summary(m4)
par(mfrow=c(2,2))
plot(m4,id.n=0)
```
Amb aquest quart model hem assolit una normalitat casi perfecta, així com una bona homocedasticitat i heterodasticitat. També podem veure que l'explicabilitat ha augmentat una mica, fins a 57.6%.

```{r}
par(mfrow=c(1,1))
residualPlots(m4,id=list(method=cooks.distance(m4),n=10))
marginalModelPlots(m4)
```
En aquests gràfics també podem comprovar com hi ha linealitat en les variables usades al model.

## Model 5
```{r}
m5<-lm(log(price)~log(mileage)+poly(tax,2)+poly(mpg,2)+poly(age,2),data=df2)
summary(m5)
vif(m5)
anova(m4, m5) #Does the variable age squared have to be included in my model
par(mfrow=c(2,2))
plot(m5)
```
Per últim, hem provat d'elaborar un model on aparegui també la variable tax i usant el quadrat de totes les variables explicatives. Com podem veure, l'explicabilitat ha augmentat a 60.2% i a més, comparant amb la funció "anova", obtenim que aquest nou model 'm5' és millor que l'anterior m4, per tant ens quedarem amb aquest com a definitiu.


# Afegim factors

```{r}
# Afegim la variable fuelType
m6 <- update(m5, ~.+fuelType,data=df2)
vif(m6)
summary(m6)
Anova(m6)
par(mfrow=c(2,2))
plot(m6,id.n=0)
# Afegim la variable transmission
m7 <- update(m6, ~.+transmission,data=df2)
summary(m7)
par(mfrow=c(2,2))
plot(m7)
vif(m7)
par(mfrow=c(1,1))
residualPlots(m7,id=list(method=cooks.distance(m7),n=10))
# Reparametrization of engine size into factor:
df2$engineSize <- as.integer(df2$engineSize)
par(mfrow=c(1,1))
hist(df2$engineSize)
quantile(df2$engineSize, c(0.33,0.66,1))
df2$engineSize2 <- factor(cut(df2$engineSize, breaks = c(0,7,11,27)))
table(df2$engineSize2)
#l'afegim
m8 <- update(m7, ~.+engineSize2,data=df2)
summary(m8)
par(mfrow=c(2,2))
plot(m8, id.n = 0)
#afegim manufacturer
m9 <- update(m8, ~.+manufacturer,data=df2)
summary(m9)
par(mfrow=c(2,2))
plot(m9, id.n = 0)
anova(m8,m9)
```
Acabem d'afegir totes les variables factor que considerem dins dels corresponents models. Com podem veure amb l'anova, l'ultim model 'm9' és el més indicat per a treballar, pero ara hi aplicarem algun canvi, eliminant o modificant variables que no ens aporten res.

```{r}
#eliminem tax1 i tax2
m9 <- update(m9, ~.-poly(tax,2),data=df2)
summary(m9)
#Include interactions
m9 <- update(m9, ~.+transmission*manufacturer,data=df2)
summary(m9)
marginalModelPlots(m9)
```
Hem eliminat del nostre model la variable 'tax' ja que no era prou significativa. També hem afegit una interacció entre factors, en aquest cas entre transmission i manufacturer, el qual ens dona informacio significativa pel nostre model i ens manté l'explicabilitat.

```{r}
m10 <- update(m9, ~.+fuelType*mpg,data=df2)
summary(m10)
anova(m9,m10)
par(mfrow=c(2,2))
plot(m10, id.n = 0)
marginalModelPlots(m10)
ll1 <- Boxplot(rstudent(m10));ll1;
```
Per últim, hem afegit la interacció entre fuelType i mpg, que ens aporta més informació rellevant al model. Donarem aquest model m10 com a definitiu per explicar la variable target 'price'.

Com podem veure al summary, l'explicabilitat és del 86.5% i a més totes les variables que apareixen al model tenen un p-value per sota de 0.05, per tant son significatives pel nostre model.

També veiem que l'homocedasticitat i heterodasticitat son correctes i tenim un model amb poques desviacions en la distribució normal.

Tenint en compte que hem passat d'un 50-60% d'explicabilitat a representar més del 85%, ens val la pena mantenir totes aquestes dades al model.



# Binary Logistics Regression

```{r}
res.cat <- catdes(df, num.var = which(names(df)=="Audi"))
res.cat$quanti.var
res.cat$test.chi2
```

From the test.chi2 we can see that model and manufacturer have something really clear with the Audi, that's because Audi is a variable made from manufacturer(yes if manufacturer is Audi and no the other way), as we have p-value of 0. Which means that we cannot use model and manufacturer as predictors.



Steps to follow:
1. Enter all relevant numerical variables in the model
2. See if you need to replace a number with its equivalent factor
3. Add to the best model of step 2, the main effects of the factors and retain the significant net effects.
4. Add interactions: between factor-factor and between factor-numeric (doubles).
5. Diagnosis of waste and observations. Lack of adjustment and / or influential.
## (1) Numerical variables
### Model 20
```{r}
model_20 <- glm(Audi~price+mileage+mpg+tax+age,family = "binomial",data=df);summary(model_20)
Anova(model_20, test="Wald") #binary target
vif(model_20)
```

Podem observar que la variable tax te un p-valor equivalent quasi a 1 el que vol dir que aquesta variable quasibé no afecta al model, per tant la treurem. 

#### Understanding the model
```{r}
plot(allEffects(model_20))
```
En aquests gràfics podem apreciar que les variables price i mileage com més alt és el valor d'aquestes més efecte tenen sobre el model. En canvi com hem dit abans la variable tax es manté sempre igual, e un percentatge d'importància baix. El gràfic de mpg disminueix tant ja que a l'haver tants pocs ctxes amb un consum tant gran, aquests quasibé no tenen efecte en el model.

```{r}
marginalModelPlots(model_20)
```
Aquí podem veure que la variable price varia molt de les dades que tenim al model que busquem, només degut a 5 outliers, per tant els eliminarem.

```{r}
residualPlots(model_20)
```
Podem apreciar que en el gràfic de price la línia no és plana sinó que fa una línia mes o menys recta cap a baix.Un altre motiu per a considerar-la factor.

```{r}
df3 <- df[!df$mout=="YesMOut",]
df3 <- df2[row.names(df2)!="27649",]
df3 <- df2[row.names(df2)!="25428",]
df3 <- df2[row.names(df2)!="8631",]
df3 <- df2[row.names(df2)!="28762",]
df3 <- df2[row.names(df2)!="4672",]
```
Aquí eliminiem manualment els outliers.

```{r}
model_20 <- glm(Audi~price+mileage+mpg+age,family = "binomial",data=df3);summary(model_20)
marginalModelPlots(model_20)
```
Després de treure els outliers podem veure com la gràfica real s'apareix més a la del model.

```{r}
residualPlots(model_20)
```
Podem apreciar que en el gràfic de price la línia ara ja és més plana i no té aquella caigud que tenia abans deguda als outliers.


Ara començarem a afegir factors al model per veure si depenen o fan canviar algun gràfic.
### Model 21
```{r}
model_21 <- glm(Audi~price+mileage+mpg+age+engineSize,family = "binomial",data=df3);summary(model_21)
vif(model_21)
anova(model_20, model_21, test="Chisq")
Anova(model_21, test="Wald") # binary target
```

```{r}
plot(allEffects(model_21))
```
Podem veure que els engineSize més petits són els que més afecten ja que són els que més quantitat n'hi ha.
```{r}
marginalModelPlots(model_21)
residualPlots(model_21)
```
Podem veure que els gràfics de la variable engineSize segueixen bastant el model previst excepte en el cas del model marginal on al final del gràfic es desvia una mica ja que per les mides més grans de motor hi ha cotxes d'altres marques que no són Audi. 


```{r}
model_22 <- glm(Audi~price+mileage+mpg+age+engineSize+transmission,family = "binomial",data=df3);summary(model_22)
vif(model_22)
anova(model_21, model_22, test="Chisq")
Anova(model_22, test="Wald") #binary target
```

```{r}
plot(allEffects(model_22))
```
Podem veure que els cotxes amb transmissió semi-automàtica són els que menys afecten ja que són els que menys quantitat n'hi ha, seguits dels que tenen transmissió automàtica.
```{r}
marginalModelPlots(model_22)
residualPlots(model_22)
```
A simple vista no podem veure cap canvi digne de donar-li importància en cap dels gràfics donats.

```{r}
model_23 <- glm(Audi~price+mileage+mpg+age+engineSize+transmission+fuelType,family = "binomial",data=df3);summary(model_23)
vif(model_23)
anova(model_22, model_23, test="Chisq")
Anova(model_23, test="Wald") #binary target
```

```{r}
plot(allEffects(model_23))
```
Més o menys tots els tipus de combustible tenen la mateixa importància ja que deu haver una quantitat pareguda de cotxes dels tres casos.
```{r}
marginalModelPlots(model_23)
residualPlots(model_23)
```

Ara canviarem dos dels 
```{r}
model_23 <- glm(Audi~price+mileage+mpg+age+engineSize+transmission+fuelType,family = "binomial",data=df3);summary(model_23)
vif(model_23)
anova(model_22, model_23, test="Chisq")
Anova(model_23, test="Wald") #binary target
```


Després d'haver afegit les variables factor que teníem podem concloure mirant els gràfics que aquestes variables no tenen relació amb la variable Audi ja que quasibé no alteren els gràfics finals.
Les conclusions que hem tret no són diferents a les que esperàvem ja que amb el dataset que teníem podíem esperar uns resultats així. Els cotxes que no són de la marca Audi són d'altres marques prou paregudes respecte al nivell de preus i luxe que oferiex Audi, amb el qual tots els altres cotxes estaven en l'estàdar d'Audi. Trobem que hagués estat diferent si hi haguessin hagut al dataset tant marques molt més cares i luxoses que Audi com d'altres menys luxoses o barates.



```{r}
fit.Audi <- factor(ifelse(predict(model_23, type="response")<0.5,0,1), labels=c("fit.no", "fit.yes"))
tt <- table(fit.Audi,df3$Audi); tt
100*sum(diag(tt)/sum(tt)) #accuracy
100*(tt[2,2]/(tt[2,2] + tt[1,2])) # recall (sensitivity)
100*(tt[1,1]/(tt[1,1] + tt[2,1])) # specificity
100*(tt[2,2]/(tt[2,1]+ tt[2,2])) # precision
```

Tenim una precisió del 78.65%. Ens dóna un 2.43% de sensitivitat, el que vol dir que els resultats positius d'aquesta confusion table són molt poc precisos. En canvi quan mirem els resultats negatius obtenim una especificitat del 98,69%, el que és un resultat molt bo. Per acabar, podem veure que la precisió dinal d'aquesta confusion table és del 32,87 %. 
